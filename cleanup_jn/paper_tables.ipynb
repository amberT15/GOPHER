{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tfr_evaluate\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add bpnet performance\n",
    "\n",
    "# add task specific vs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_entries = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_results = pd.concat([pd.read_csv(f) for f in \n",
    "                                 ['/mnt/31dac31c-c4e2-4704-97bd-0788af37c5eb/model_evaluations/binloss_basenji.csv', \n",
    "                                    '/mnt/31dac31c-c4e2-4704-97bd-0788af37c5eb/model_evaluations/base_res.csv',\n",
    "                                   '/mnt/31dac31c-c4e2-4704-97bd-0788af37c5eb/model_evaluations/ADDED_base_res.csv',\n",
    "                                   '/mnt/31dac31c-c4e2-4704-97bd-0788af37c5eb/model_evaluations/32_res.csv',\n",
    "                                    '/mnt/31dac31c-c4e2-4704-97bd-0788af37c5eb/model_evaluations/ADDED_bin_loss_40.csv',\n",
    "                                    '/mnt/31dac31c-c4e2-4704-97bd-0788af37c5eb/model_evaluations/bin_loss_40.csv'\n",
    "                                   ]])\n",
    "\n",
    "eval_type = 'whole'\n",
    "pred_type = 'raw'\n",
    "\n",
    "\n",
    "raw_whole_perf = performance_results[(performance_results['eval type']==eval_type)&\n",
    "                                    (performance_results['pred type']==pred_type)&\n",
    "                                   ((performance_results['bin_size']==32)| (performance_results['bin_size']==1))\n",
    "                                    &(performance_results['loss_fn']=='poisson')]\n",
    "\n",
    "raw_whole_perf = raw_whole_perf[raw_whole_perf['run_dir']!='paper_runs/new_models/base_res/run-20211022_222400-1pt92q45']\n",
    "descriptions = raw_whole_perf.iloc[:,7:]\n",
    "avg_perf = raw_whole_perf.groupby('run_dir').mean().reset_index()\n",
    "\n",
    "avg_perf_complete = avg_perf.merge(descriptions, how='left', left_on='run_dir',right_on='run_dir').drop_duplicates(subset='run_dir')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basenji_w1_b64 0.5768\n",
      "conv_profile_task_base (exponential) 0.5988\n",
      "bpnet 0.6008\n",
      "conv_profile_task_base (relu) 0.607\n",
      "residual_profile_task_base (relu) 0.6369\n",
      "residual_profile_all_base (relu) 0.6425\n",
      "residual_profile_task_base (exponential) 0.6536\n",
      "residual_profile_all_base (exponential) 0.6552\n",
      "conv_profile_all_dense_32 (exponential) 0.5416\n",
      "conv_profile_all_dense_32 (relu) 0.5468\n",
      "bpnet 0.583\n",
      "basenjimod 0.5845\n",
      "conv_profile_task_conv_32 (exponential) 0.5964\n",
      "conv_profile_task_base (exponential) 0.6014\n",
      "conv_profile_task_base (relu) 0.604\n",
      "conv_profile_task_conv_32 (relu) 0.6188\n",
      "residual_profile_all_dense_32 (relu) 0.6548\n",
      "residual_profile_all_dense_32 (exponential) 0.6652\n",
      "residual_profile_task_conv_32 (relu) 0.6699\n",
      "residual_profile_task_conv_32 (exponential) 0.6766\n"
     ]
    }
   ],
   "source": [
    "for g, df in avg_perf_complete[['model_fn', 'bin_size_x', 'pr_corr', 'activation', 'run_dir']].groupby('bin_size_x'):\n",
    "    for i, row in (df[['model_fn', 'pr_corr', 'activation', 'run_dir']].sort_values('pr_corr')).iterrows():\n",
    "#         if row.values[3] == 'paper_runs/basenji/base_res/run-20211022_222400-1pt92q45':\n",
    "        if row['activation'] == row['activation']:\n",
    "        \n",
    "            print('{} ({})'.format(row.values[0], row['activation']),  np.round(row.values[1], 4))\n",
    "        else:\n",
    "            print(row.values[0], np.round(row.values[1], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset, targets, target_dataset_idr = tfr_evaluate.collect_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_size = 32\n",
    "filepath = 'paper_tables/32_res_eval_bins.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm paper_tables/32_res_eval_bins.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "32 ---> 32\n",
      "32 ---> 64\n",
      "32 ---> 128\n",
      "32 ---> 256\n",
      "32 ---> 512\n",
      "32 ---> 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shush/tf_2/lib/python3.7/site-packages/scipy/spatial/distance.py:1300: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(js / 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 ---> 2048\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(filepath):\n",
    "    best_base_model = avg_perf_complete[avg_perf_complete['bin_size_x']==bin_size].sort_values(['pr_corr']).iloc[-1,0]\n",
    "\n",
    "    # evaluate at all bin sizes \n",
    "    model, raw_bin_size = tfr_evaluate.read_model(best_base_model)\n",
    "    all_true, all_pred = tfr_evaluate.get_true_pred(model, raw_bin_size, testset)\n",
    "\n",
    "\n",
    "    bin_sizes = [1, 32, 64, 128, 256, 512, 1024, 2048]\n",
    "    performance_per_resolution = []\n",
    "    for eval_bin_size in bin_sizes:\n",
    "        if eval_bin_size>=raw_bin_size:\n",
    "            print(raw_bin_size, '--->', eval_bin_size)\n",
    "            true_for_eval = tfr_evaluate.change_resolution(all_true, raw_bin_size, eval_bin_size)\n",
    "            pred_for_eval = tfr_evaluate.change_resolution(all_pred, raw_bin_size, eval_bin_size)\n",
    "            performance = tfr_evaluate.get_performance(true_for_eval, pred_for_eval, targets, 'whole')\n",
    "            performance_per_resolution.append([raw_bin_size, eval_bin_size] + list(performance.mean().values))\n",
    "\n",
    "    sorted_personr = pd.DataFrame(performance_per_resolution, columns=['train', 'eval']+list(performance.columns[:-1].values)).sort_values(['train', 'eval'])[['train', 'eval', 'pr_corr']]\n",
    "    sorted_personr['run_dir'] = best_base_model\n",
    "    sorted_personr.to_csv(filepath, index=None)\n",
    "else:\n",
    "    sorted_personr = pd.read_csv(filepath, index_col=None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 0.677\n",
      "64 0.679\n",
      "128 0.684\n",
      "256 0.692\n",
      "512 0.7\n",
      "1024 0.707\n",
      "2048 0.704\n"
     ]
    }
   ],
   "source": [
    "for _,row in (sorted_personr).iterrows():\n",
    "    print(int(row['eval']), np.round(row['pr_corr'], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
